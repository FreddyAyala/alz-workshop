# Lab 1: Deploying ALZ with the Terraform Accelerator (PowerShell Module)

In this lab, you will deploy the Azure Landing Zone foundation using the official ALZ Terraform Accelerator PowerShell module. This is the Microsoft-recommended, production-grade method for bootstrapping an ALZ environment.

## Step 1: Install the ALZ PowerShell Module

1.  **Open PowerShell 7:** This lab requires PowerShell 7 (`pwsh.exe`).
2.  **Check for Existing Module:** Run `Get-InstalledModule -Name ALZ`.
3.  **Install or Update:**
    *   If the module is installed, run `Update-Module -Name ALZ` to get the latest version.
    *   If it is not installed, run `Install-Module -Name ALZ -Scope CurrentUser`.

## Step 2: Create the Accelerator Configuration Files

The accelerator is driven by configuration files. We will create a dedicated folder structure for them.

1.  **Create Directories:**
    ```powershell
    New-Item -ItemType Directory -Path '.\accelerator\config' -Force
    New-Item -ItemType Directory -Path '.\accelerator\output' -Force
    ```

2.  **Create `inputs.yaml`:** This file defines the core settings. Create the file `.\accelerator\config\inputs.yaml` with the following content.
    *   **Action Required:** You must replace `<management-subscription-id>` with a valid Subscription ID. For this lab, you can use the same ID for management, identity, and connectivity.

    ```yaml
    iac_type: terraform
    bootstrap_module_name: alz_local
    starter_module_name: platform_landing_zone
    bootstrap_location: eastus
    starter_locations:
      - eastus
      - westus2
    root_parent_management_group_id: ""
    subscription_id_management: <management-subscription-id>
    subscription_id_identity: <management-subscription-id>
    subscription_id_connectivity: <management-subscription-id>
    service_name: alz
    environment_name: mgmt
    postfix_number: 1
    ```

3.  **Create `platform-landing-zone.tfvars`:** This file configures the ALZ module itself. For now, we will use a minimal configuration to deploy the default hub and spoke network. Create the file `.\accelerator\config\platform-landing-zone.tfvars`:
    ```terraform
    # No custom values needed for a default deployment.
    # The accelerator will use the module's default variables.
    ```

## Step 3: Run the Accelerator

1.  **Run the `Deploy-Accelerator` Command:**
    From the root of your project, run the following command. The module will read your configuration files and begin the deployment.

    ```powershell
    Deploy-Accelerator `
    -inputs ".\accelerator\config\inputs.yaml", ".\accelerator\config\platform-landing-zone.tfvars" `
    -output ".\accelerator\output"
    ```

2.  **Approve the Terraform Plan:** The script will initialize Terraform, create a plan, and then pause for you to review. If you are happy with the planned changes, press **Enter** to continue.

3.  **Monitor the Deployment:** The deployment will take 20-30 minutes. It will create a local Terraform project in the `output` folder and apply it.

## Step 4: Validate the Deployment

1.  **Check the Azure Portal:** Once the script completes, navigate to the **Management Groups** service in the Azure portal.
2.  **Verify the Hierarchy:** You should see the `alz` management group hierarchy. The top-level management group will be named `alzroot`.
3.  **Check Resources:** In the management subscription, you will see new resource groups created by the bootstrap process, such as `rg-alz-mgmt-identity-eastus-001` and `rg-alz-mgmt-state-eastus-001`.
4.  **Review the Generated Code:** The accelerator creates a complete Terraform project in the `.\accelerator\output\local-output` directory. Inspect this directory to see the generated `.tf` files that define your ALZ environment.

You have now successfully deployed the ALZ foundation using the correct and verified accelerator method.

---

# Lab 2: Deploying the Hub Network Manually with AVMs

The code generated by the accelerator is complex and has proven unreliable during our tests. For a clearer and more robust workshop experience, we will deploy the hub network manually using the official Azure Verified Modules (AVMs). This demonstrates the core components of ALZ networking directly.

## Step 1: Set Up the Hub Network Terraform Configuration

1.  **Create a New Directory:** Navigate back to the root of the project and create a new folder for our hub network.
    ```powershell
    cd ..\..\.. # Navigate back to the project root
    New-Item -ItemType Directory -Path '.\hub-network' -Force
    cd .\hub-network
    ```
2.  **Create `main.tf`:** Create a `main.tf` file. This will define the hub VNet, firewall, and bastion host.

```terraform
terraform {
  required_version = ">= 1.5"
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
          version = "~> 3.0"
        }
      }
      backend "azurerm" {
        resource_group_name  = "rg-alz-mgmt-state-eastus-001"
        storage_account_name = "stoalzmgmeas001laxe"
        container_name       = "tfstate"
        key                  = "hub-network.tfstate"
        use_azuread_auth     = true
      }
}

provider "azurerm" {
  features {}
      subscription_id = var.connectivity_subscription_id
    }

    variable "connectivity_subscription_id" {
      type        = string
      description = "The subscription ID for the connectivity resources. Use the one from Lab 1."
    }

    variable "location" {
      type        = string
      default     = "eastus"
      description = "The Azure region for deployment."
    }

    resource "azurerm_resource_group" "hub" {
      name     = "rg-alz-hub-network-eastus-001"
      location = var.location
    }

    module "hub_vnet" {
      source  = "Azure/avm-res-network-virtualnetwork/azurerm"
      version = "0.9.3"

      name                = "vnet-alz-hub-eastus-001"
      resource_group_name = azurerm_resource_group.hub.name
      location            = azurerm_resource_group.hub.location
      address_space       = ["10.0.0.0/16"]

      subnets = {
        AzureFirewallSubnet = {
          address_prefixes = ["10.0.1.0/24"]
        }
        AzureBastionSubnet = {
          address_prefixes = ["10.0.2.0/24"]
        }
        GatewaySubnet = {
          address_prefixes = ["10.0.3.0/24"]
        }
      }
    }

    # Azure Firewall
    resource "azurerm_public_ip" "firewall" {
      name                = "pip-azfw-hub-eastus-001"
      location            = azurerm_resource_group.hub.location
      resource_group_name = azurerm_resource_group.hub.name
      allocation_method   = "Static"
      sku                 = "Standard"
    }

    resource "azurerm_firewall" "hub" {
      name                = "azfw-alz-hub-eastus-001"
      location            = azurerm_resource_group.hub.location
      resource_group_name = azurerm_resource_group.hub.name
      sku_name            = "AZFW_VNet"
      sku_tier            = "Standard"

      ip_configuration {
        name                 = "configuration"
        subnet_id            = module.hub_vnet.subnets["AzureFirewallSubnet"].id
        public_ip_address_id = azurerm_public_ip.firewall.id
      }
    }

    # Azure Bastion
    resource "azurerm_public_ip" "bastion" {
      name                = "pip-bastion-hub-eastus-001"
      location            = azurerm_resource_group.hub.location
      resource_group_name = azurerm_resource_group.hub.name
      allocation_method   = "Static"
      sku                 = "Standard"
    }

    resource "azurerm_bastion_host" "hub" {
      name                = "bastion-alz-hub-eastus-001"
      location            = azurerm_resource_group.hub.location
      resource_group_name = azurerm_resource_group.hub.name

      ip_configuration {
        name                 = "configuration"
        subnet_id            = module.hub_vnet.subnets["AzureBastionSubnet"].id
        public_ip_address_id = azurerm_public_ip.bastion.id
      }
    }

    output "hub_vnet_id" {
      value = module.hub_vnet.id
    }
    ```

## Step 2: Deploy the Hub Network

1.  **Ensure you are logged into Azure:** This step is crucial to ensure Terraform has a valid authentication context.
    ```powershell
    az login
    ```
2.  **Initialize Terraform:**
    ```bash
    terraform init -reconfigure
    ```
3.  **Deploy:** When prompted, enter the Subscription ID you used for connectivity in Lab 1 (e.g., `de80dbb8-a2dc-4ba1-8058-af99f88c8de1`).
```bash
    terraform apply
    ```

## Step 3: Validate the Deployment

1.  **Check the Portal:** In the connectivity subscription, you should see a new resource group `rg-alz-hub-network-eastus-001`.
2.  **Verify Resources:** Inside, you will find the `vnet-alz-hub-eastus-001`, `azfw-alz-hub-eastus-001`, and `bastion-alz-hub-eastus-001`.

---

# Lab 3: Vending a Spoke Network

Now we will vend a spoke network and connect it to our manually deployed hub.

## Step 1: Set Up the Spoke Terraform Configuration

1.  **Create a Directory:**
    ```powershell
    cd .. # Navigate back to the project root
    New-Item -ItemType Directory -Path '.\spoke-landing-zone' -Force
    cd .\spoke-landing-zone
    ```
2.  **Create `main.tf`:**

    ```terraform
    terraform {
      required_version = ">= 1.5"
      required_providers {
        azurerm = {
          source  = "hashicorp/azurerm"
          version = "~> 3.0"
        }
      }
      backend "azurerm" {
        resource_group_name  = "rg-alz-mgmt-state-eastus-001"
        storage_account_name = "stoalzmgmeas001laxe"
        container_name       = "tfstate"
        key                  = "spoke-network.tfstate"
        use_azuread_auth     = true
      }
    }

    provider "azurerm" {
      features {}
      subscription_id = var.spoke_subscription_id
    }

    variable "spoke_subscription_id" {
      type        = string
      description = "The subscription ID for the spoke landing zone."
    }

    data "terraform_remote_state" "hub" {
      backend = "azurerm"
      config = {
        resource_group_name  = "rg-alz-mgmt-state-eastus-001"
        storage_account_name = "stoalzmgmeas001laxe"
        container_name       = "tfstate"
        key                  = "hub-network.tfstate"
      }
    }

    module "app_spoke_landing_zone" {
      source  = "Azure/lz-vending/azurerm"
      version = "~> 5.2"

      location = "eastus"
      subscription_alias_enabled = false

      virtual_network_enabled = true
      virtual_networks = {
        primary = {
          name                = "vnet-app-prod-eastus-001"
          address_space       = ["10.100.0.0/16"]
          resource_group_name = "rg-app-prod-network-eastus-001"
          hub_peering_enabled     = true
          hub_network_resource_id = data.terraform_remote_state.hub.outputs.hub_vnet_id
        }
      }
    }
    ```

## Step 2: Deploy and Validate the Spoke

After running `terraform apply` (providing a subscription ID for the spoke), check the **Peerings** blade on the hub VNet to validate the connection.
